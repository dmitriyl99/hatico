{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE EXTRACTION\n",
    "The main concept used here is to extract features from the images using pretrained Models and train on them.\n",
    "To increase the generalization we can extract features using many different models, concatenate them and use them together.\n",
    "In this way, we can achieve high accuracy even without using high end GPU's\n",
    "I have written the main code in the form of functions, so that you can use them easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for garbage collection\n",
    "import gc\n",
    "\n",
    "# for warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# utility libraries\n",
    "import os\n",
    "import copy\n",
    "import tqdm\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import cv2, random, time, shutil, csv\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "# keras libraries\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import BatchNormalization, Dense, GlobalAveragePooling2D, Lambda, Dropout, InputLayer, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of classes read - 120\n"
     ]
    }
   ],
   "source": [
    "# set image size here\n",
    "img_size = 331\n",
    "data_dir = 'datasets'\n",
    "data_df = pd.read_csv(os.path.join(data_dir, 'labels.csv'))\n",
    "class_names = sorted(data_df['breed'].unique())\n",
    "print(f\"No. of classes read - {len(class_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = sorted(os.listdir(os.path.join(data_dir, 'train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [00:41<00:00, 245.74it/s]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "i = 0\n",
    "for image in tqdm.tqdm(images_list):\n",
    "    cls_name = data_df[data_df['id'] == image[:-4]].iloc[0, 1]\n",
    "    cls_index = int(class_names.index(cls_name)) \n",
    "\n",
    "    # Reading RGB Images\n",
    "    image_path = os.path.join(data_dir, 'train', image)\n",
    "    orig_image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "    res_image = cv2.resize(orig_image,(img_size, img_size))\n",
    "    X.append(res_image)\n",
    "    Y.append(cls_index)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10222 10222\n",
      "(10222, 331, 331, 3) (10222, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting to arrays\n",
    "print(len(X), len(Y))\n",
    "Xarr = np.array(X)\n",
    "Yarr = np.array(Y).reshape(-1,1)\n",
    "\n",
    "del(X)\n",
    "print(Xarr.shape, Yarr.shape)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10222, 331, 331, 3) (10222, 120)\n"
     ]
    }
   ],
   "source": [
    "# converting labels to one hot\n",
    "Yarr_hot = to_categorical(Y)\n",
    "print(Xarr.shape, Yarr_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE EXTRACTION OF TRAINING ARRAYS\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "def get_features(model, data_preprocessor, data):\n",
    "    '''\n",
    "    1- Create a feature extractor to extract features from the data.\n",
    "    2- Returns the extracted features and the feature extractor.\n",
    "\n",
    "    '''\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "\n",
    "    def preprocess(image):\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.random_brightness(image, 0.5)\n",
    "        return image\n",
    "    \n",
    "    ds = dataset.map(preprocess, num_parallel_calls=AUTO).batch(64)\n",
    "    input_size = data.shape[1:]\n",
    "    #Prepare pipeline.\n",
    "    input_layer = Input(input_size)\n",
    "    preprocessor = Lambda(data_preprocessor)(input_layer)\n",
    "\n",
    "    base_model = model(weights='imagenet', include_top=False, input_shape=input_size)(preprocessor)\n",
    "    avg = GlobalAveragePooling2D()(base_model)\n",
    "    feature_extractor = Model(inputs=input_layer, outputs=avg)\n",
    "    #Extract feature.\n",
    "    feature_maps = feature_extractor.predict(ds, verbose=1)\n",
    "    print('Feature maps shape: ', feature_maps.shape)\n",
    "    # deleting variables\n",
    "    del(feature_extractor, base_model, preprocessor, dataset)\n",
    "    gc.collect()\n",
    "    return feature_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE EXTRACTION OF VALIDAION AND TESTING ARRAYS\n",
    "def get_valfeatures(model, data_preprocessor, data):\n",
    "    '''\n",
    "    Same as above except not image augmentations applied.\n",
    "    Used for feature extraction of validation and testing.\n",
    "    '''\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "\n",
    "    ds = dataset.batch(64)\n",
    "\n",
    "    input_size = data.shape[1:]\n",
    "    #Prepare pipeline.\n",
    "    input_layer = Input(input_size)\n",
    "    preprocessor = Lambda(data_preprocessor)(input_layer)\n",
    "\n",
    "    base_model = model(weights='imagenet', include_top=False,\n",
    "                                input_shape=input_size)(preprocessor)\n",
    "\n",
    "    avg = GlobalAveragePooling2D()(base_model)\n",
    "    feature_extractor = Model(inputs = input_layer, outputs = avg)\n",
    "    #Extract feature.\n",
    "    feature_maps = feature_extractor.predict(ds, verbose=1)\n",
    "    print('Feature maps shape: ', feature_maps.shape)\n",
    "    return feature_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RETURNING CONCATENATED FEATURES USING MODELS AND PREPROCESSORS\n",
    "def get_concat_features(feat_func, models, preprocs, array):\n",
    "\n",
    "    print(f\"Beggining extraction with {feat_func.__name__}\\n\")\n",
    "    feats_list = []\n",
    "\n",
    "    for i in range(len(models)):\n",
    "        \n",
    "        print(f\"\\nStarting feature extraction with {models[i].__name__} using {preprocs[i].__name__}\\n\")\n",
    "        # applying the above function and storing in list\n",
    "        feats_list.append(feat_func(models[i], preprocs[i], array))\n",
    "\n",
    "    # features concatenating\n",
    "    final_feats = np.concatenate(feats_list, axis=-1)\n",
    "    # memory saving\n",
    "    del(feats_list, array)\n",
    "    gc.collect()\n",
    "\n",
    "    return final_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINING models and preprocessors imports \n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "inception_preprocessor = preprocess_input\n",
    "\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "xception_preprocessor = preprocess_input\n",
    "\n",
    "from keras.applications.nasnet import NASNetLarge, preprocess_input\n",
    "nasnet_preprocessor = preprocess_input\n",
    "\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "inc_resnet_preprocessor = preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [InceptionV3,  InceptionResNetV2, Xception, ]\n",
    "preprocs = [inception_preprocessor,  inc_resnet_preprocessor, \n",
    "            xception_preprocessor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beggining extraction with get_features\n",
      "\n",
      "\n",
      "Starting feature extraction with InceptionV3 using preprocess_input\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-04 01:17:55.882049: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 532s 3s/step\n",
      "Feature maps shape:  (10222, 2048)\n",
      "\n",
      "Starting feature extraction with InceptionResNetV2 using preprocess_input\n",
      "\n",
      "160/160 [==============================] - 1228s 8s/step\n",
      "Feature maps shape:  (10222, 1536)\n",
      "\n",
      "Starting feature extraction with Xception using preprocess_input\n",
      "\n",
      "160/160 [==============================] - 902s 6s/step\n",
      "Feature maps shape:  (10222, 2048)\n",
      "Final feature maps shape (10222, 5632)\n"
     ]
    }
   ],
   "source": [
    "# calculating features of the data\n",
    "\n",
    "final_train_features = get_concat_features(get_features, models, preprocs, Xarr)\n",
    "print('Final feature maps shape', final_train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "EarlyStop_callback = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True,\n",
    "                                                   verbose=0)\n",
    "\n",
    "my_callback=[EarlyStop_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "splits = list(StratifiedKFold(n_splits=3, shuffle=True, random_state=10).split(final_train_features, Y))\n",
    "\n",
    "trained_models = []\n",
    "accuracy = []\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting fold 1\n",
      "\n",
      "Training...\n",
      "Evaluating model ...\n",
      "107/107 [==============================] - 0s 1ms/step - loss: 0.2358 - accuracy: 0.9281\n",
      "\n",
      "Starting fold 2\n",
      "\n",
      "Training...\n",
      "Evaluating model ...\n",
      "107/107 [==============================] - 0s 853us/step - loss: 0.2777 - accuracy: 0.9213\n",
      "\n",
      "Starting fold 3\n",
      "\n",
      "Training...\n",
      "Evaluating model ...\n",
      "107/107 [==============================] - 0s 873us/step - loss: 0.2541 - accuracy: 0.9219\n",
      "\n",
      " CV Score -\n",
      "\n",
      "Accuracy - 0.9237913886706034\n",
      "\n",
      "Loss - 0.2558705310026805\n"
     ]
    }
   ],
   "source": [
    "#Prepare And Train DNN model\n",
    "\n",
    "for i, (train_idx, valid_idx) in enumerate(splits): \n",
    "\n",
    "    print(f\"\\nStarting fold {i+1}\\n\")\n",
    "    x_train_fold = final_train_features[train_idx, :]\n",
    "    y_train_fold = Yarr_hot[train_idx, :]\n",
    "    x_val_fold = final_train_features[valid_idx]\n",
    "    y_val_fold = Yarr_hot[valid_idx, :]\n",
    "\n",
    "    dnn = keras.models.Sequential([\n",
    "        InputLayer(final_train_features.shape[1:]),\n",
    "        Dropout(0.7),\n",
    "        Dense(120, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    dnn.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    print(\"Training...\")\n",
    "    #Train simple DNN on extracted features.\n",
    "    h = dnn.fit(x_train_fold, y_train_fold,\n",
    "                batch_size=128,\n",
    "                epochs=80,\n",
    "                verbose=0,\n",
    "                validation_data = (x_val_fold, y_val_fold),\n",
    "                callbacks=my_callback)  # max 95.07\n",
    "\n",
    "    print(\"Evaluating model ...\")\n",
    "    model_res = dnn.evaluate(x_val_fold, y_val_fold)\n",
    "\n",
    "    accuracy.append(model_res[1])\n",
    "    losses.append(model_res[0])\n",
    "    trained_models.append(dnn)\n",
    "\n",
    "print('\\n CV Score -')\n",
    "print(f\"\\nAccuracy - {sum(accuracy)/len(accuracy)}\")\n",
    "print(f\"\\nLoss - {sum(losses)/len(losses)}\")\n",
    "\n",
    "for i in range(0, 3):\n",
    "    trained_models[i].save(f'models/model_{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f7bb26e0911db3ccc600e51703592838f5fb1a7df456b38433da9c570b2a6f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
